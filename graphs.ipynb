{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import shapely.geometry\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "current_palette = sns.color_palette()\n",
    "cmap = ListedColormap(sns.color_palette(current_palette).as_hex())\n",
    "\n",
    "sns.set(rc={'figure.figsize':(10,4)}, font_scale=1.0, style='whitegrid', font='CMU Sans Serif')\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "# this is where we will store all the graphs\n",
    "graph_folder = os.path.join(\".\", \"graphs\")\n",
    "os.makedirs(graph_folder, exist_ok=True)\n",
    "\n",
    "def save_fig(ax: plt.Axes, folder: str, name: str, format=\"pdf\"):\n",
    "    fig = ax.get_figure()\n",
    "    fig.tight_layout()\n",
    "\n",
    "    fig.savefig(os.path.join(folder, f\"{name}.{format}\"), bbox_inches='tight')\n",
    "    fig.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step one: get all the location data\n",
    "groups = pd.read_csv(os.path.join(\".\", \"groups.csv\"))\n",
    "groups[\"SENSOR_ID\"] = groups[\"SENSOR_ID\"].astype(str)\n",
    "affinity = pd.read_csv(os.path.join(\".\", \"affinity.csv\"))\n",
    "locations = pd.read_csv(\"locations.csv\")\n",
    "\n",
    "buoy_locations = locations[locations[\"type\"] == \"sensor\"]\n",
    "\n",
    "# to get the links between buoys and sinks, we need to do a few joins here\n",
    "# first add buoy lat/lng to the groups\n",
    "groups = groups.merge(locations[[\"id\", \"lat\", \"lng\"]], left_on=\"SENSOR_ID\", right_on=\"id\")\n",
    "\n",
    "# then add the station lat/lng to the affinity\n",
    "affinity = affinity.merge(locations[[\"id\", \"lat\", \"lng\"]], left_on=\"STATION_ID\", right_on=\"id\")\n",
    "\n",
    "# then merge the affinity with the groups\n",
    "total_groups = affinity.merge(groups, on=\"GROUP\", suffixes=(\"_sink\", \"_buoy\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step two: read all the data\n",
    "experiment_duration = 15 * 60 * 1e3\n",
    "start_offset = 5 * 60 * 1e3\n",
    "\n",
    "df_experiment = pd.DataFrame()\n",
    "\n",
    "for run_name in [\"cloud\", \"sat\"]:\n",
    "    for run_number in [\"1\", \"2\", \"3\"]:\n",
    "\n",
    "        results_dir = os.path.join(\".\", \"results\", f\"results-{run_name}-{run_number}\")\n",
    "        files = os.listdir(os.path.join(\".\", results_dir))\n",
    "\n",
    "        # first we find out the start time of the experiment\n",
    "        # the actual start time is the latest \"first\" entry in all of the files\n",
    "        start_time = 0.0\n",
    "        for f in files:\n",
    "            with open(os.path.join(\".\", results_dir, f)) as fp:\n",
    "                # get an iterator\n",
    "                lines = iter(fp)\n",
    "                # skip the first line\n",
    "                next(lines)\n",
    "                # split the first data line and\n",
    "                # get send_time_1\n",
    "                send_time_1 = int(next(lines).split(\",\")[4])\n",
    "\n",
    "                if send_time_1 > start_time:\n",
    "                    start_time = send_time_1\n",
    "\n",
    "        # convert start_time to milliseconds\n",
    "        start_time = start_time / 1e6\n",
    "        start_time += start_offset\n",
    "\n",
    "        for f in files:\n",
    "\n",
    "            try:\n",
    "                client = f[len(\"cesink\"):-len(\".ext4-results.csv\")]\n",
    "\n",
    "                df_run = pd.read_csv(os.path.join(\".\", results_dir, f))\n",
    "                df_run[\"client\"] = client\n",
    "                df_run[\"run_name\"] = run_name\n",
    "                df_run[\"run_number\"] = run_number\n",
    "\n",
    "                # convert to milliseconds\n",
    "                df_run[\"send_time1\"] = df_run[\"send_time1\"] / 1e6\n",
    "                df_run[\"send_time2\"] = df_run[\"send_time2\"] / 1e6\n",
    "                df_run[\"recv_time1\"] = df_run[\"recv_time1\"] / 1e6\n",
    "                df_run[\"recv_time2\"] = df_run[\"recv_time2\"] / 1e6\n",
    "\n",
    "                # now we need to filter out by start_time and duration\n",
    "                # consider send_time_1 for this\n",
    "                df_run = df_run[(df_run[\"send_time1\"] >= start_time) & (df_run[\"send_time1\"] <= start_time + experiment_duration)]\n",
    "                df_run.reset_index(inplace=True)\n",
    "\n",
    "                df_run[\"send_latency1\"] = df_run[\"recv_time1\"] - df_run[\"send_time1\"]\n",
    "                df_run[\"send_latency2\"] = df_run[\"recv_time2\"] - df_run[\"send_time2\"]\n",
    "                df_run[\"processing_latency\"] = df_run[\"send_time2\"] - df_run[\"recv_time1\"]\n",
    "                df_run[\"total_latency\"] = df_run[\"recv_time2\"] - df_run[\"send_time1\"]\n",
    "\n",
    "                df_run[\"latency\"] = df_run[\"recv_time2\"] - df_run[\"send_time1\"]\n",
    "\n",
    "                df_experiment = df_experiment.append(pd.DataFrame({\n",
    "                    \"client\": client,\n",
    "                    \"run_name\": run_name,\n",
    "                    \"run_number\": run_number,\n",
    "                    \"lat\": locations.loc[locations[\"id\"] == client, \"lat\"].values[0],\n",
    "                    \"lng\": locations.loc[locations[\"id\"] == client, \"lng\"].values[0],\n",
    "                    # at this point we only really care about mean total latency\n",
    "                    \"latency\": df_run[\"total_latency\"].mean(),\n",
    "                }, index=[0]))\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading file {f}\")\n",
    "                raise e\n",
    "\n",
    "df_experiment.dropna(inplace=True)\n",
    "df_experiment.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2f/b2y6thfs2051_m0fs57vb_sc0000gn/T/ipykernel_38405/1674366253.py:36: MatplotlibDeprecationWarning: Auto-removal of grids by pcolor() and pcolormesh() is deprecated since 3.5 and will be removed two minor releases later; please call grid(False) first.\n",
      "  cbar = ax.figure.colorbar(sm, location=\"bottom\", shrink=0.35, aspect=10, anchor=(0.85, 1), pad=-0.15)\n",
      "webf NOT subset; don't know how to subset; dropped\n",
      "/var/folders/2f/b2y6thfs2051_m0fs57vb_sc0000gn/T/ipykernel_38405/1674366253.py:36: MatplotlibDeprecationWarning: Auto-removal of grids by pcolor() and pcolormesh() is deprecated since 3.5 and will be removed two minor releases later; please call grid(False) first.\n",
      "  cbar = ax.figure.colorbar(sm, location=\"bottom\", shrink=0.35, aspect=10, anchor=(0.85, 1), pad=-0.15)\n",
      "webf NOT subset; don't know how to subset; dropped\n",
      "/var/folders/2f/b2y6thfs2051_m0fs57vb_sc0000gn/T/ipykernel_38405/1674366253.py:36: MatplotlibDeprecationWarning: Auto-removal of grids by pcolor() and pcolormesh() is deprecated since 3.5 and will be removed two minor releases later; please call grid(False) first.\n",
      "  cbar = ax.figure.colorbar(sm, location=\"bottom\", shrink=0.35, aspect=10, anchor=(0.85, 1), pad=-0.15)\n",
      "webf NOT subset; don't know how to subset; dropped\n",
      "/var/folders/2f/b2y6thfs2051_m0fs57vb_sc0000gn/T/ipykernel_38405/1674366253.py:36: MatplotlibDeprecationWarning: Auto-removal of grids by pcolor() and pcolormesh() is deprecated since 3.5 and will be removed two minor releases later; please call grid(False) first.\n",
      "  cbar = ax.figure.colorbar(sm, location=\"bottom\", shrink=0.35, aspect=10, anchor=(0.85, 1), pad=-0.15)\n",
      "webf NOT subset; don't know how to subset; dropped\n",
      "/var/folders/2f/b2y6thfs2051_m0fs57vb_sc0000gn/T/ipykernel_38405/1674366253.py:36: MatplotlibDeprecationWarning: Auto-removal of grids by pcolor() and pcolormesh() is deprecated since 3.5 and will be removed two minor releases later; please call grid(False) first.\n",
      "  cbar = ax.figure.colorbar(sm, location=\"bottom\", shrink=0.35, aspect=10, anchor=(0.85, 1), pad=-0.15)\n",
      "webf NOT subset; don't know how to subset; dropped\n",
      "/var/folders/2f/b2y6thfs2051_m0fs57vb_sc0000gn/T/ipykernel_38405/1674366253.py:36: MatplotlibDeprecationWarning: Auto-removal of grids by pcolor() and pcolormesh() is deprecated since 3.5 and will be removed two minor releases later; please call grid(False) first.\n",
      "  cbar = ax.figure.colorbar(sm, location=\"bottom\", shrink=0.35, aspect=10, anchor=(0.85, 1), pad=-0.15)\n",
      "webf NOT subset; don't know how to subset; dropped\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cmap = sns.color_palette(\"viridis\", as_cmap=True)\n",
    "vmin = 10\n",
    "vmax = 190\n",
    "\n",
    "for name in [\"cloud\", \"sat\"]:\n",
    "    for run in [\"1\", \"2\", \"3\"]:\n",
    "        fig, ax = plt.subplots(figsize=(5, 4), subplot_kw={'projection': ccrs.PlateCarree(central_longitude=180)})\n",
    "\n",
    "        ax.add_feature(cartopy.feature.BORDERS, linestyle='-', alpha=1, edgecolor=(\"#FFFFFF\"))\n",
    "        ax.add_feature(cartopy.feature.LAND, facecolor=(\"#d4d4d4\"))\n",
    "\n",
    "        ax.set_xlim(-60, 110)\n",
    "        ax.set_ylim(-60, 60)\n",
    "\n",
    "        ax.grid(False)\n",
    "\n",
    "        # we need to plot the buoy locations for everyhing to make sense\n",
    "        sns.scatterplot(ax=ax, data=buoy_locations, x=\"lng\", y=\"lat\", transform=ccrs.Geodetic(), zorder=10, linewidth=0, alpha=0.8, color=\"black\", marker=\"X\", size=0.5)\n",
    "\n",
    "        # and then add the data\n",
    "        # just remembered that seaborn doesn't do vmin and vmax properly\n",
    "        df = df_experiment[(df_experiment[\"run_name\"] == name) & (df_experiment[\"run_number\"] == run)]\n",
    "        # sns.scatterplot(ax=ax, data=df, x=\"lng\", y=\"lat\",hue=\"latency\", palette=cmap, transform=ccrs.Geodetic(), zorder=10, linewidth=0, alpha=0.8, vmin=vmin, vmax=vmax)\n",
    "        ax.scatter(x=df[\"lng\"], y=df[\"lat\"], cmap=cmap, c=df[\"latency\"], transform=ccrs.PlateCarree(), zorder=10, linewidth=0, alpha=0.8, vmin=vmin, vmax=vmax)\n",
    "\n",
    "        # and also the links between things\n",
    "        for g in range(total_groups.shape[0]):\n",
    "            ax.plot([total_groups[\"lng_sink\"][g], total_groups[\"lng_buoy\"][g]], [total_groups[\"lat_sink\"][g], total_groups[\"lat_buoy\"][g]], linewidth=0.5, alpha=0.25, color=\"gray\", markersize=1, zorder=10, transform=ccrs.Geodetic())\n",
    "\n",
    "        # now add a colorbar\n",
    "\n",
    "        norm = plt.Normalize(vmin, vmax)\n",
    "        sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "        sm.set_array(np.ndarray([]))\n",
    "        ax.get_legend().remove()\n",
    "        cbar = ax.figure.colorbar(sm, location=\"bottom\", shrink=0.35, aspect=10, anchor=(0.85, 1), pad=-0.15)\n",
    "        cbar.ax.xaxis.set_major_formatter(matplotlib.ticker.FormatStrFormatter('%dms'))\n",
    "        # custom ticks to get it a bit more spaced out\n",
    "        cbar.ax.xaxis.set_ticks([25, 100, 175])\n",
    "        cbar.outline.set_visible(True)\n",
    "        cbar.outline.set_color(\"black\")\n",
    "        ax.axis('off')\n",
    "        # plt.show()\n",
    "        save_fig(ax, graph_folder, f\"buoys-{name}-{run}\")\n",
    "        # ax.clear()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
